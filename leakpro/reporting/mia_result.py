"""Contains the Result classes for MIA, MiNVA, and GIA attacks."""

import os
import pickle

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import auc

from leakpro.reporting.report_utils import get_config_name, reduce_to_unique_labels
from leakpro.schemas import MIAResultSchema
from leakpro.utils.import_helper import Self
from leakpro.utils.logger import logger


class MIAResult:
    """Contains results related to the performance of the metric."""

    def __init__(  # noqa: PLR0913
        self:Self,
        true_membership: list=None,
        signal_values:list=None,
        metadata: dict = None,
        result_name: str = None,
        id: str = None,
        tp_fp_tn_fn: tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray] = None
    )-> None:
        """Compute and store the accuracy, ROC AUC score, and the confusion matrix for a metric.

        Args:
        ----
            true_membership: True membership labels used to evaluate the metrics.
            signal_values: Signal values generated by the attack. Large signal values are indicative of membership.
            id: The identity of the attack
            metadata: Metadata about the results
            result_name: The name of the attack and result
            tp_fp_tn_fn: Tuple containing the true positives, false positives, true negatives, and false negatives
                         (this is used if the attack does not support arbitrary threshold value or does not create signal values).

        """
        self.true = np.ravel(true_membership)
        self.signal_values = signal_values
        self.metadata = metadata
        self.result_name = result_name
        self.id = id

        if tp_fp_tn_fn is not None:
            self.tp = tp_fp_tn_fn[0]
            self.fp = tp_fp_tn_fn[1]
            self.tn = tp_fp_tn_fn[2]
            self.fn = tp_fp_tn_fn[3]
        else:
            # Compute results
            # Sort signal_values in descending order and align labels
            sorted_indices = np.argsort(-np.ravel(self.signal_values))
            sorted_labels = self.true[sorted_indices]
            sorted_scores = self.signal_values[sorted_indices]

            # Cumulative true positives and false positives as we move threshold from high to low
            tp_cumsum = np.cumsum(sorted_labels == 1)
            fp_cumsum = np.cumsum(sorted_labels == 0)

            # Unique thresholds (indices returned start from low values)
            thresholds, first_indices = np.unique(sorted_scores, return_index=True)
            # Reverse the order to start from high values
            thresholds = thresholds[::-1]
            first_indices = first_indices[::-1]

            # Collect values at points where threshold changes
            self.tp = tp_cumsum[first_indices]
            self.fp = fp_cumsum[first_indices]
            self.fn = (np.sum(sorted_labels == 1) - tp_cumsum[first_indices])
            self.tn = (np.sum(sorted_labels == 0) - fp_cumsum[first_indices])

        self.fpr = np.where(self.fp + self.tn != 0, self.fp / (self.fp + self.tn), 0.0)
        self.tpr = np.where(self.tp + self.fn != 0, self.tp / (self.tp + self.fn), 0.0)

        self.accuracy = (self.tp + self.tn) / (self.tp + self.fp + self.fn + self.tn)

        def _get_length(x: np.ndarray) -> int:
            """Get the length of the input."""
            try:
                return len(x)
            except TypeError:
                return 1  # Single value
        # if too few unique values, it is not possible to compute ROC AUC

        if _get_length(self.fpr) < 2:
            logger.warning("Too few unique values to compute ROC AUC")
            self.roc_auc = 0.0
            self.fixed_fpr_table = {}
            self.fpr = [0.0, 1.0]
            self.tpr = [0.0, 1.0]

        else:
            self.roc_auc = auc(self.fpr, self.tpr)

            fpr_targets = [0.0, 0.0001, 0.001, 0.01, 0.1]
            self.fixed_fpr_table = self._get_result_fixed_fpr(fpr_targets)



    def _get_result_fixed_fpr(self: Self, fpr_targets: list[float]) -> dict:
        """Find TPR values for fixed FPRs.

        Args:
        ----
            fpr_targets: List of FPR targets to compute TPR for.

        """
        results = {}

        for fpr_target in fpr_targets:
            # Get indices where FPR is less than or equal to the target
            valid_indices = np.where(self.fpr <= fpr_target)[0]

            if len(valid_indices) > 0:
                valid_index = valid_indices[-1]
                tpr = self.tpr[valid_index]
            else:
                tpr = 0.0

            results[f"TPR@{fpr_target:.1%}FPR"] = tpr

        return results

    def _get_roc_auc_in_fpr_interval(self:Self, ub:float) -> float:
        """Calculate the average TPR for FPR values below fpr_threshold.

        Args:
        ----
            ub: The upper bound of the FPR interval.

        """
        # Check if the FPR values are less than or equal to the upper bound
        if len(self.fpr) <= 2:
            return 0.0
        mask = self.fpr < ub
        return float(np.mean(self.tpr[mask]))

    def save(self:Self, path: str, name: str, config:dict = None) -> None:
        """Save the MIAResults to disk."""

        result_config = config.attack_list[name]
        if not isinstance(result_config, dict):
            if hasattr(result_config, "model_dump"):
                result_config = result_config.model_dump()
            elif result_config is None:
                result_config = {}

        # Get the name for the attack configuration
        config_name = get_config_name(result_config)

        self.id = f"{name}{config_name}".replace("/", "__")
        save_path = f"{path}/{name}/{self.id}"

        # Data to be saved
        mia_data = MIAResultSchema(
            result_name = self.result_name,
            result_type = self.__class__.__name__,
            tpr = self.tpr,
            fpr = self.fpr,
            roc_auc = self.roc_auc,
            accuracy = self.accuracy,
            config = result_config,
            fixed_fpr = self.fixed_fpr_table,
            signal_values = self.signal_values if self.signal_values is not None else [0.0],
            true_labels = self.true if self.true is not None else [0],
            id = self.id,
            tp_fp_tn_fn=(self.tp, self.fp, self.tn, self.fn) if self.signal_values is None else None
        )

        # Check if path exists, otherwise create it.
        if not os.path.exists(save_path):
            os.makedirs(save_path)

        # Save the results to a file
        with open(f"{save_path}/data.json", "wb") as f:
            pickle.dump(mia_data, f)

        # Create ROC plot
        if len(self.fpr) > 1:
            logger.info(f"Creating ROC plot for {name}")
            self.create_roc_plot([self], save_dir = save_path, save_name = name)

        # Create SignalHistogram plot for MIAResult
        if self.signal_values is not None:
            logger.info(f"Creating SignalHistogram plot for {name}")
            self.create_signal_histogram(save_path = save_path)

    @staticmethod
    def load(mia_data:MIAResultSchema) -> Self:
        """Load MIAResults from disk."""

        assert isinstance(mia_data, MIAResultSchema), "mia_data must be of type MIAResultSchema"

        mia_data.true_labels = np.array(mia_data.true_labels)
        mia_data.signal_values = np.array(mia_data.signal_values)

        return MIAResult(
            true_membership = mia_data.true_labels,
            signal_values = mia_data.signal_values,
            metadata = mia_data.config,
            result_name = mia_data.result_name,
            id = mia_data.id,
            tp_fp_tn_fn = mia_data.tp_fp_tn_fn
        )

    def create_signal_histogram(self:Self, save_path: str) -> None:
        """Method to create Signal Histogram."""

        filename = f"{save_path}/SignalHistogram"
        values = np.array(self.signal_values).ravel()
        labels = np.array(self.true).ravel()

        # Split values by membership
        member_values = values[labels == 1]
        non_member_values = values[labels == 0]

        # Compute bin edges (shared for both histograms)
        bin_edges = np.histogram_bin_edges(values, bins=1000)

        # Plot histograms
        plt.hist(non_member_values, bins=bin_edges, histtype="step", label="out-member", density=False)
        plt.hist(member_values, bins=bin_edges, histtype="step", label="in-member", density=False)

        plt.grid()
        plt.xlabel("Signal value")
        plt.ylabel("Number of samples")
        plt.title("Signal histogram")
        plt.legend()
        plt.tight_layout()
        plt.savefig(fname=filename + ".png", dpi=1000)
        plt.clf()

    @staticmethod
    def create_roc_plot(result_objects:list, save_dir: str = "", save_name: str = "") -> None:
        """Plot method for MIAResult. This method can be used by individual result objects or multiple.

        Args:
        ----
            result_objects (list): List of MIAResult objects to plot.
            save_dir (str): Directory to save the plot.
            save_name (str): Name of the plot.

        """

        filename = f"{save_dir}/{save_name}"

        # Create plot for results
        assert isinstance(result_objects, list), "Results must be a list of MIAResult objects"

        reduced_labels = reduce_to_unique_labels(result_objects)
        for res, label in zip(result_objects, reduced_labels):

            plt.fill_between(res.fpr, res.tpr, alpha=0.15)
            plt.plot(res.fpr, res.tpr, label=label)

        # Plot baseline (random guess)
        range01 = np.linspace(0, 1)
        plt.plot(range01, range01, "--", label="Random guess")

        # Set plot parameters
        plt.yscale("log")
        plt.xscale("log")
        plt.xlim(left=1e-5)
        plt.ylim(bottom=1e-5)
        plt.tight_layout()
        plt.grid()
        plt.legend(bbox_to_anchor =(0.5,-0.27), loc="lower center")

        plt.xlabel("False positive rate (FPR)")
        plt.ylabel("True positive rate (TPR)")
        plt.title(save_name+" ROC Curve")
        plt.savefig(fname=f"{filename}.png", dpi=1000, bbox_inches="tight")
        plt.clf()

    @staticmethod
    def get_strongest(results: list) -> list:
        """Method for selecting the strongest attack."""
        return max((res for res in results), key=lambda d: d.roc_auc)

    @staticmethod
    def _get_all_attacknames(results: list) -> list:
        attack_name_list = []
        for result in results:
            if result.result_name not in attack_name_list:
                attack_name_list.append(result.result_name)
        return attack_name_list

    @staticmethod
    def _get_results_of_name(
            results: list,
            result_name_value: str
            ) -> list:
        indices = [idx for (idx, result) in enumerate(results) if result.result_name == result_name_value]
        return [results[idx] for idx in indices]

    @staticmethod
    def create_results(
            results: list,
            save_dir: str = "./",
        ) -> str:
        """Result method for MIAResult."""
        latex = ""

        # Create plot for all results
        MIAResult.create_roc_plot(results, save_dir, save_name="all_results")
        latex += MIAResult._latex(results, save_dir, save_name="all_results")

        # Create plot for results grouped by name
        all_attack_names = MIAResult._get_all_attacknames(results)
        for name in all_attack_names:
            results_name_grouped = MIAResult._get_results_of_name(results, name)
            MIAResult.create_roc_plot(results_name_grouped, save_dir, save_name=name)
            latex += MIAResult._latex(results_name_grouped, save_dir, save_name=name)

        # Create plot for results grouped by name
        grouped_results = [MIAResult._get_results_of_name(results, name) for name
                           in all_attack_names]
        strongest_results = [MIAResult.get_strongest(result) for result in grouped_results]
        MIAResult.create_roc_plot(strongest_results, save_dir, save_name="strongest")
        latex += MIAResult._latex(strongest_results, save_dir, save_name="strongest")

        return latex

    @staticmethod
    def _latex(
            results: list,
            save_dir: str, # noqa: ARG004
            save_name: str
        ) -> str:
        """Latex method for MIAResult."""

        # Input mia results image
        latex_content = f"""
        \\subsection{{{" ".join(save_name.split("_"))}}}
        \\begin{{figure}}[ht]
        \\includegraphics[width=0.8\\textwidth]{{{save_name}.png}}
        \\end{{figure}}
        """

        # Initialize latex table
        latex_content += """
        \\resizebox{\\linewidth}{!}{%
        \\begin{tabularx}{\\textwidth}{l c l l l l}
        Attack name & attack config & TPR: 10.0\\%FPR & 1.0\\%FPR & 0.1\\%FPR & 0.0\\%FPR \\\\ \\hline """ # noqa: W291

        # Convert config to latex table input
        def config_latex_style(config: str) -> str:
            config = " \\\\ ".join(config.split("-")[1:])
            config = "-".join(config.split("_"))
            return f"""\\shortstack{{{config}}}"""

        # Append all mia results to table
        for res in results:
            config = config_latex_style(res.id)
            latex_content += f"""
            {"-".join(res.result_name.split("_"))} & {config} & {res.fixed_fpr_table["TPR@10.0%FPR"]} & {res.fixed_fpr_table["TPR@1.0%FPR"]} & {res.fixed_fpr_table["TPR@0.1%FPR"]} & {res.fixed_fpr_table["TPR@0.0%FPR"]} \\\\ \\hline """ # noqa: E501
        latex_content += """
        \\end{tabularx}
        }
        \\newline
        """
        return latex_content
